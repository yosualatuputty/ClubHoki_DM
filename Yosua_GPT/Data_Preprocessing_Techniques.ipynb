{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d525177",
   "metadata": {},
   "source": [
    "\n",
    "# Data Preprocessing Techniques in Python\n",
    "This notebook covers the most important data preprocessing techniques used in data science, including:\n",
    "- Handling missing data\n",
    "- Encoding categorical variables\n",
    "- Feature scaling\n",
    "- Feature selection\n",
    "- Outlier detection and handling\n",
    "- Data normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35786397",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import IsolationForest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51a29e-df15-45f5-b3a5-21690e8e4183",
   "metadata": {},
   "source": [
    "## 1. Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a797d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "    age   salary         city\n",
      "0  25.0  50000.0     New York\n",
      "1  30.0  60000.0  Los Angeles\n",
      "2   NaN      NaN     New York\n",
      "3  35.0  80000.0      Chicago\n",
      "4  40.0  90000.0          NaN\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Impute missing categorical values with the most frequent value\u001b[39;00m\n\u001b[0;32m     17\u001b[0m imputer \u001b[38;5;241m=\u001b[39m SimpleImputer(strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmost_frequent\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m imputer\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData after handling missing values:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\frame.py:4091\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4088\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4090\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4091\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\frame.py:4300\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4292\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4293\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4298\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4299\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4300\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4303\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4304\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4305\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4306\u001b[0m     ):\n\u001b[0;32m   4307\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4308\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\frame.py:5040\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5038\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   5039\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m-> 5040\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\construction.py:608\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    606\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m--> 608\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    610\u001b[0m         object_index\n\u001b[0;32m    611\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[0;32m    612\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[0;32m    613\u001b[0m     ):\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[0;32m    615\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\py311\\Lib\\site-packages\\pandas\\core\\dtypes\\cast.py:1172\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[1;34m(value)\u001b[0m\n\u001b[0;32m   1169\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;28mtype\u001b[39m(value))  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1171\u001b[0m     \u001b[38;5;66;03m# Caller is responsible\u001b[39;00m\n\u001b[1;32m-> 1172\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(value\u001b[38;5;241m.\u001b[39mndim)  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m   1175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[1;31mValueError\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "# Create sample data with missing values\n",
    "data = {\n",
    "    'age': [25, 30, np.nan, 35, 40],\n",
    "    'salary': [50000, 60000, np.nan, 80000, 90000],\n",
    "    'city': ['New York', 'Los Angeles', 'New York', 'Chicago', np.nan]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original Data:\")\n",
    "print(df)\n",
    "\n",
    "# Impute missing numerical values with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['age'] = imputer.fit_transform(df[['age']])\n",
    "df['salary'] = imputer.fit_transform(df[['salary']])\n",
    "\n",
    "# Impute missing categorical values with the most frequent value\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['city'] = imputer.fit_transform(df[['city']])\n",
    "\n",
    "print(\"\\nData after handling missing values:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe715679-5066-485a-b3ae-6329abdbf142",
   "metadata": {},
   "source": [
    "## 2. Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab0ccfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Label Encoding for ordinal data\n",
    "label_encoder = LabelEncoder()\n",
    "df['city_label'] = label_encoder.fit_transform(df['city'])\n",
    "print(\"\\nData after Label Encoding:\")\n",
    "print(df)\n",
    "\n",
    "# One-Hot Encoding for nominal data\n",
    "df_onehot = pd.get_dummies(df, columns=['city'])\n",
    "print(\"\\nData after One-Hot Encoding:\")\n",
    "print(df_onehot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad2bf08-687f-40a5-bae1-692d20a5773c",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3083f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Standardization (Z-score scaling)\n",
    "scaler = StandardScaler()\n",
    "df['age_scaled'] = scaler.fit_transform(df[['age']])\n",
    "df['salary_scaled'] = scaler.fit_transform(df[['salary']])\n",
    "print(\"\\nData after Standardization:\")\n",
    "print(df)\n",
    "\n",
    "# Min-Max Scaling (Normalization)\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df['age_minmax'] = minmax_scaler.fit_transform(df[['age']])\n",
    "df['salary_minmax'] = minmax_scaler.fit_transform(df[['salary']])\n",
    "print(\"\\nData after Min-Max Scaling:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526a33fa-c92a-417f-8568-a8f3f8289918",
   "metadata": {},
   "source": [
    "## 4. Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b410857",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Feature selection using SelectKBest with chi-squared (for categorical target variable)\n",
    "\n",
    "# Create a sample dataset\n",
    "X = df[['age', 'salary']]\n",
    "y = df['city_label']  # Example target\n",
    "\n",
    "# Apply SelectKBest to select top 1 feature\n",
    "selector = SelectKBest(chi2, k=1)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "print(\"\\nFeatures selected by SelectKBest (top 1):\")\n",
    "print(X_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3107669d-d56e-4ff7-8f8d-aa18b13e4c63",
   "metadata": {},
   "source": [
    "## 5. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08930ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data with potential outliers:\n",
      "    age  salary\n",
      "0    25   50000\n",
      "1    30   60000\n",
      "2    35   70000\n",
      "3    40   80000\n",
      "4  1000   90000\n",
      "\n",
      "Data after outlier detection (-1 indicates outlier):\n",
      "    age  salary  outlier\n",
      "0    25   50000        1\n",
      "1    30   60000        1\n",
      "2    35   70000        1\n",
      "3    40   80000        1\n",
      "4  1000   90000       -1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Create a sample dataset\n",
    "data_outliers = {'age': [25, 30, 35, 40, 1000], 'salary': [50000, 60000, 70000, 80000, 90000]}\n",
    "df_outliers = pd.DataFrame(data_outliers)\n",
    "print(\"\\nData with potential outliers:\")\n",
    "print(df_outliers)\n",
    "\n",
    "# Using Isolation Forest to detect outliers\n",
    "iso_forest = IsolationForest(contamination=0.2)\n",
    "outliers = iso_forest.fit_predict(df_outliers)\n",
    "df_outliers['outlier'] = outliers\n",
    "print(\"\\nData after outlier detection (-1 indicates outlier):\")\n",
    "print(df_outliers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f8d03c-1d07-470a-b6d0-0ece008a12d0",
   "metadata": {},
   "source": [
    "## 6. Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3809e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Using Min-Max Scaling to normalize data between 0 and 1\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m df_normalized[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m minmax_scaler\u001b[38;5;241m.\u001b[39mfit_transform(df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msalary\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mData after normalization:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Using Min-Max Scaling to normalize data between 0 and 1\n",
    "df_normalized = df.copy()\n",
    "df_normalized[['age', 'salary']] = minmax_scaler.fit_transform(df[['age', 'salary']])\n",
    "print(\"\\nData after normalization:\")\n",
    "print(df_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934638fa-5276-4c01-b8fd-64f4dbd9624b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyh311",
   "language": "python",
   "name": "pyh311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
