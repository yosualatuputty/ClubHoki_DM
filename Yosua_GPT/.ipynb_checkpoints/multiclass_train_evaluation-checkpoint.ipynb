{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Multiclass Classification using Multiple Models\n",
                "In this notebook, we will perform multiclass classification using various machine learning models and evaluate them using **F1-macro-average** as the evaluation metric. The goal is to find the model that achieves the best result.\n",
                "\n",
                "### Models to be used:\n",
                "- Logistic Regression\n",
                "- Random Forest\n",
                "- Support Vector Machine (SVM)\n",
                "- k-Nearest Neighbors (k-NN)\n",
                "- Gradient Boosting Classifier\n",
                "\n",
                "We will use the **Iris dataset** for this task and compare the F1-macro-average of each model to find the best performing one."
            ]
        },
        {
            "cell_type": "code",
    
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.metrics import f1_score\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.datasets import load_iris\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.svm import SVC\n",
                "from sklearn.neighbors import KNeighborsClassifier\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 1: Load the Iris dataset\n",
                "We'll start by loading the Iris dataset, which contains 3 classes and 4 features."
            ]
        },
        {
            "cell_type": "code",
        
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the Iris dataset\n",
                "data = load_iris()\n",
                "X = data.data\n",
                "y = data.target\n",
                "\n",
                "# Split the data into training and testing sets\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 2: Train Different Models\n",
                "We will now train five different machine learning models and evaluate them using the F1-macro-average score."
            ]
        },
        {
            "cell_type": "code",
          
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the models\n",
                "models = {\n",
                "    'Logistic Regression': LogisticRegression(max_iter=200),\n",
                "    'Random Forest': RandomForestClassifier(random_state=42),\n",
                "    'SVM': SVC(),\n",
                "    'k-NN': KNeighborsClassifier(),\n",
                "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
                "}\n",
                "\n",
                "# Dictionary to store F1 macro-average scores\n",
                "f1_scores = {}\n",
                "\n",
                "# Train each model and calculate F1-macro-average\n",
                "for model_name, model in models.items():\n",
                "    model.fit(X_train, y_train)\n",
                "    y_pred = model.predict(X_test)\n",
                "    f1_macro_avg = f1_score(y_test, y_pred, average='macro')\n",
                "    f1_scores[model_name] = f1_macro_avg\n",
                "    print(f'{model_name} F1 Macro-Average: {f1_macro_avg:.4f}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 3: Visualizing the F1-Macro-Average Scores\n",
                "We will now plot the F1-macro-average scores for each model to compare their performance."
            ]
        },
        {
            "cell_type": "code",
   
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the F1 macro-average scores for each model\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.barplot(x=list(f1_scores.keys()), y=list(f1_scores.values()), palette='viridis')\n",
                "plt.title('F1 Macro-Average Score for Different Models')\n",
                "plt.ylabel('F1 Macro-Average')\n",
                "plt.xlabel('Model')\n",
                "plt.xticks(rotation=45)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Step 4: Conclusion\n",
                "We have evaluated multiple models using the F1-macro-average score. The model with the highest score performs best for this multiclass classification task. You can now experiment with tuning hyperparameters or using different datasets for further improvements."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.7.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}

