{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "238b1e99",
   "metadata": {},
   "source": [
    "# Time Series Modeling Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aec120",
   "metadata": {},
   "source": [
    "In this notebook, we will explore how to create a time series forecasting model using Python. The dataset used here contains a time series with regular intervals, and we will walk through key steps such as stationarity checks, model selection, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48c0c1f",
   "metadata": {},
   "source": [
    "## Step 1: Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc905b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset (replace 'your_data.csv' with your actual file path)\n",
    "df = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Convert the date column to datetime and set as index\n",
    "df['date_column'] = pd.to_datetime(df['date_column'])\n",
    "df.set_index('date_column', inplace=True)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b877fcf1",
   "metadata": {},
   "source": [
    "## Step 2: Data Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the time series data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['value_column'], label='Time Series')\n",
    "plt.title('Time Series Plot')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Values')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb162ca",
   "metadata": {},
   "source": [
    "## Step 3: Stationarity Check and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be56dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the Augmented Dickey-Fuller test from statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Perform the ADF test\n",
    "result = adfuller(df['value_column'])\n",
    "\n",
    "# Print the ADF statistic and p-value\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "\n",
    "# If p-value > 0.05, the data is not stationary. Differencing the data to remove trend:\n",
    "df['value_diff'] = df['value_column'].diff().dropna()\n",
    "df['value_diff'].plot(title='Differenced Time Series')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b16602",
   "metadata": {},
   "source": [
    "## Step 4: Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc179dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df.iloc[:train_size], df.iloc[train_size:]\n",
    "\n",
    "# Plot the training and test sets\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train['value_column'], label='Train Set')\n",
    "plt.plot(test['value_column'], label='Test Set', color='orange')\n",
    "plt.title('Train-Test Split')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c2dd5",
   "metadata": {},
   "source": [
    "## Step 5: Build an ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b063f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import ARIMA from statsmodels\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Build the ARIMA model (replace p, d, q with actual values after inspecting ACF/PACF plots)\n",
    "model = ARIMA(train['value_column'], order=(5, 1, 0))  # Example: (p, d, q) = (5, 1, 0)\n",
    "fitted_model = model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(fitted_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c1aee8",
   "metadata": {},
   "source": [
    "## Step 6: Forecasting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Forecast on the test data\n",
    "predictions = fitted_model.forecast(steps=len(test))\n",
    "\n",
    "# Import mean_squared_error to calculate RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test['value_column'], predictions))\n",
    "print(f'RMSE: {rmse}')\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test['value_column'], label='Actual')\n",
    "plt.plot(predictions, label='Predicted', color='red')\n",
    "plt.title('Actual vs Predicted')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb61ab2",
   "metadata": {},
   "source": [
    "## Step 7: Model Tuning and Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f980d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model using joblib\n",
    "import joblib\n",
    "\n",
    "# Save the fitted model\n",
    "joblib.dump(fitted_model, 'arima_model.pkl')\n",
    "print(\"Model saved as arima_model.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ae6a48-e8dc-4b44-a323-698dce795cb9",
   "metadata": {},
   "source": [
    "## Step 8: Export CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdfdc42-d44a-4e58-889b-211b6ee35835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions to a CSV file\n",
    "output = pd.DataFrame({'Actual': test['value_column'], 'Predicted': predictions})\n",
    "output.to_csv('predictions_output.csv', index=True)\n",
    "\n",
    "print(\"Predictions saved to predictions_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyh311",
   "language": "python",
   "name": "pyh311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
