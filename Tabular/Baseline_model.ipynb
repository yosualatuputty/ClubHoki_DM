{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Baseline to Better Model: A Journey in Machine Learning\n",
    "\n",
    "## Introduction\n",
    "In this notebook, we will explore how a simple baseline model can be improved using various techniques and methods in machine learning. We will compare performance metrics at each stage to understand the impact of these changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "We will use the Iris dataset for this demonstration. First, let's install the necessary libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip install -U scikit-learn pandas seaborn\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Explore the Dataset\n",
    "The Iris dataset is a classic dataset in machine learning. Let's load it and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df = pd.DataFrame(data=X, columns=iris.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Baseline Model with Logistic Regression\n",
    "We'll start by creating a simple baseline model using Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize and train the baseline model\n",
    "baseline_model = LogisticRegression(max_iter=200)\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "\n",
    "# Evaluate the baseline model\n",
    "print('Baseline Model Performance')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_baseline))\n",
    "print('Classification Report:\n",
    "', classification_report(y_test, y_pred_baseline))\n",
    "print('Confusion Matrix:\n",
    "', confusion_matrix(y_test, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Improving the Model with Random Forest\n",
    "Next, we'll implement a Random Forest Classifier to see if we can improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest model\n",
    "print('Random Forest Model Performance')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_rf))\n",
    "print('Classification Report:\n",
    "', classification_report(y_test, y_pred_rf))\n",
    "print('Confusion Matrix:\n",
    "', confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Further Improvement with Support Vector Machine (SVM)\n",
    "Now, we'll try using a Support Vector Machine to see if we can achieve even better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the SVM model\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Evaluate the SVM model\n",
    "print('SVM Model Performance')\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred_svm))\n",
    "print('Classification Report:\n",
    "', classification_report(y_test, y_pred_svm))\n",
    "print('Confusion Matrix:\n",
    "', confusion_matrix(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Comparison of Models\n",
    "Now, let's compare the performances of all three models visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting accuracies for comparison\n",
    "model_names = ['Baseline (Logistic Regression)', 'Random Forest', 'SVM']\n",
    "accuracies = [accuracy_score(y_test, y_pred_baseline),\n",
    "              accuracy_score(y_test, y_pred_rf),\n",
    "              accuracy_score(y_test, y_pred_svm)]\n",
    "\n",
    "# Create a bar plot for comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=model_names, y=accuracies)\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this notebook, we started with a simple baseline model using Logistic Regression and progressively improved our model using Random Forest and Support Vector Machines. Each step demonstrated an increase in performance metrics, illustrating the importance of model selection and enhancement in machine learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
